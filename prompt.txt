this code is in tensorflow and it contains: 
demo_HQHS_recon.py {import numpy as np
import cv2
import scipy.io as sio

import params
import modulation

import autoencoder.model as ae_model
import recon.snapshot.reconstruction as HQHS_recon

def demo_recon(SINGLE_CASSI=False,
               SSCSI=True,
               rho=1e-01,
               sparsity=1e-02,
               lambda_alpha_fidelity=1e-01,
               lr=5.0e-02,
               iters_ADMM=10,
               iters_ADAM=100,
               filename_test='',
               out_filename='',
               out_coded_img_filename='',
               summary_dir=''
               ):
    #########################################################
    # define the shape of the model
    #########################################################
    test_n_features_encoder = ae_model.default_n_features_encoder
    test_layer_type_encoder = ae_model.default_layer_type_encoder
    test_n_features_decoder = ae_model.default_n_features_decoder
    test_layer_type_decoder = ae_model.default_layer_type_decoder
    trained_model_filename = params.FILENAME_DEFAULT_MODEL
    #########################################################
    # read inputs
    #########################################################
    mat_obj = sio.loadmat(file_name=filename_test)
    gt_hs = mat_obj['img_hs']
    gt_hs = gt_hs.astype(np.float32) / 65535.0

    img_h, img_w, img_chs = gt_hs.shape
    mask_2d = modulation.generate_random_mask(h=img_h, w=img_w, scale=1.0)

    # generate coded image
    list_dispersion = np.arange(0, 31)
    if SINGLE_CASSI:
        list_dispersion = np.floor(list_dispersion * 0.5)
        list_dispersion = list_dispersion.astype(dtype=np.int32)
        print(list_dispersion)

    if SSCSI:
        mask3d = modulation.shift_random_mask(mask_2d, shift=0.1)
    else:
        mask3d = modulation.generate_shifted_mask_cube(mask_2d, shift_list=list_dispersion,
                                                       SINGLE_CASSI=SINGLE_CASSI)

    img_snapshot = modulation.generate_coded_image(gt_hs, mask3d,
                                                   SINGLE_CASSI=SINGLE_CASSI,
                                                   shift_list=list_dispersion)

    img_snapshot = np.squeeze(img_snapshot)
    cv2.imwrite(out_coded_img_filename, img_snapshot * 255 * 3)
    cv2.imshow('coded image', img_snapshot)
    print('Press any keys to continue!')
    cv2.waitKey()

    #########################################################
    # run reconstructing
    #########################################################
    x_recon, wvls2b = HQHS_recon.recon_snapshot(img_snapshot=img_snapshot,
                                                img_mask=mask_2d,
                                                gt_hs=gt_hs,
                                                out_filename=out_filename,
                                                img_n_chs=31,
                                                list_shift=list_dispersion,
                                                SINGLE_CASSI=SINGLE_CASSI,
                                                SSCSI=SSCSI,
                                                param_rho=rho,
                                                param_sparsity=sparsity,
                                                param_lambda_alpha_fidelity=lambda_alpha_fidelity,
                                                param_learning_rate=lr,
                                                n_iters_ADMM=iters_ADMM,
                                                n_iters_ADAM=iters_ADAM,
                                                ENABLE_ALPHA_FIDELITY=True,
                                                list_n_features_encoder=test_n_features_encoder,
                                                list_layer_type_encoder=test_layer_type_encoder,
                                                list_n_features_decoder=test_n_features_decoder,
                                                list_layer_type_decoder=test_layer_type_decoder,
                                                filename_model=trained_model_filename,
                                                do_summarize=True,
                                                summary_dir=summary_dir)
    print(x_recon.shape)
    print(wvls2b)

    cv2.waitKey()


def demo_recon_synthetic_CAVE():
    #########################################################
    # Select Modulation Type
    #########################################################
    SINGLE_CASSI = False
    SSCSI = True

    #########################################################
    # params for CAVE dataset
    #########################################################
    rho = 1e-01
    sparsity = 0.01
    lambda_alpha_fidelity = 1e-01
    lr = 5.0e-02
    iters_ADMM = 10
    iters_ADAM = 100
    filename_test = './inputs/synthetic/CAVE/103.mat'
    out_filename = './outputs/recon_synthetic/103_recon.mat'
    out_coded_img_filename = './outputs/recon_synthetic/103_coded_img.png'
    summary_dir = './outputs/recon_synthetic/103_recon_summary'


    #########################################################
    # Do recon
    #########################################################
    demo_recon(SINGLE_CASSI=SINGLE_CASSI,
               SSCSI=SSCSI,
               rho=rho,
               sparsity=sparsity,
               lambda_alpha_fidelity=lambda_alpha_fidelity,
               lr=lr,
               iters_ADMM=iters_ADMM,
               iters_ADAM=iters_ADAM,
               filename_test=filename_test,
               out_filename=out_filename,
               out_coded_img_filename=out_coded_img_filename,
               summary_dir=summary_dir)

def demo_recon_synthetic_KAIST():
    #########################################################
    # Select Modulation Type
    #########################################################
    SINGLE_CASSI = False
    SSCSI = True

    #########################################################
    # params for KAIST dataset
    #########################################################
    rho = 7.5e-02
    sparsity = 1e-02
    lambda_alpha_fidelity = 1e-01
    lr = 5.0e-02
    iters_ADMM = 20
    iters_ADAM = 200
    filename_test = './inputs/synthetic/KAIST/scene03.mat'
    out_filename = './outputs/recon_synthetic/scene03_recon.mat'
    out_coded_img_filename = './outputs/recon_synthetic/scene03_coded_img.png'
    summary_dir = './outputs/recon_synthetic/scene03_recon_summary'

    #########################################################
    # Do recon
    #########################################################
    demo_recon(SINGLE_CASSI=SINGLE_CASSI,
               SSCSI=SSCSI,
               rho=rho,
               sparsity=sparsity,
               lambda_alpha_fidelity=lambda_alpha_fidelity,
               lr=lr,
               iters_ADMM=iters_ADMM,
               iters_ADAM=iters_ADAM,
               filename_test=filename_test,
               out_filename=out_filename,
               out_coded_img_filename=out_coded_img_filename,
               summary_dir=summary_dir)


if __name__=='__main__':
   #demo_recon_synthetic_CAVE()
   demo_recon_synthetic_KAIST()} 

modulation.py {import params
import numpy as np
import cv2



shift_ours = [24, 19, 14, 9, 4, 0,
              -4, -7, -11, -14, -17,
              -20, -23, -25, -28, -30,
              -32, -34, -36, -38, -40, -42,
              -43, -45, -46, -48, -49, -50,
              -51, -53, -54, -56, -57]


def generate_random_mask(h=512, w=512, scale=1):
    mask = np.random.randint(0, 2, size=(int(h / scale), int(w / scale))).astype(np.float32)
    if scale != 1.0:
        mask = cv2.resize(mask, dsize=(w, h), interpolation=cv2.INTER_NEAREST)
    return mask


def shift_random_mask(mask, chs=31, shift=0.1):
    h, w = mask.shape

    shifted_mask = np.zeros(shape=(h, w, chs), dtype=mask.dtype)

    for j in range(h):
        for i in range(w):
            for ch in range(chs):
                m = int(round((1 - shift) * i + shift * ch))
                if m > w:
                    m = m - w
                if m < 0:
                    m = m + w

                shifted_mask[j, i, ch] = mask[j, m]

    # for ch in range(chs):
    #     vis.imshow_with_zoom(wname='shifted mask', img=shifted_mask[:,:,ch]*255,
    #                          scale=1.0, interpolation=cv2.INTER_NEAREST)
    #     cv2.waitKey()
    return shifted_mask

def shift_random_mask_for_real(mask, chs=31, shift_list=[]):
    h, w = mask.shape
    shifted_mask = np.zeros(shape=(h, w, chs), dtype=mask.dtype)

    # disperse the coded mask
    for ch in range(chs):
        # for ch in params.VALID_SPECTRAL_CHS:
        shift_val = shift_list[ch]
        M = np.float32([[1, 0, shift_val], [0, 1, 0]])
        dst = cv2.warpAffine(mask, M, (w, h))
        #img_coded_mask_shifted = np.roll(mask, shift=shift_val, axis=1)
        #cv2.imshow('mask ch:' + str(ch), dst)
        #cv2.waitKey()
        shifted_mask[:, :, ch] = dst

    return shifted_mask


def generate_shifted_mask_cube(mask, chs=31,
                               shift_list=shift_ours,
                               shift_list_y=np.zeros(shape=(1,31)),
                               SINGLE_CASSI=False):
    h, w = mask.shape
    shifted_mask = np.zeros(shape=(h, w, chs), dtype=mask.dtype)

    # disperse the coded mask
    for ch in range(chs):
        # for ch in params.VALID_SPECTRAL_CHS:
        if SINGLE_CASSI:
            img_coded_mask_shifted = mask
        else:
            #shift_val = shift_list[ch]
            #img_coded_mask_shifted = np.roll(mask, shift=shift_val, axis=1)
            shift_val = shift_list[ch]
            shift_val_y = shift_list_y[ch]
            M = np.float32([[1, 0, shift_val], [0, 1, shift_val_y]])
            img_coded_mask_shifted = cv2.warpAffine(mask, M, (w, h))
        shifted_mask[:, :, ch] = img_coded_mask_shifted

    return shifted_mask


def generate_coded_image(img_hs, mask, chs=31, SINGLE_CASSI=False, shift_list=shift_ours):
    img_masked = np.multiply(img_hs, mask)
    if SINGLE_CASSI:
        # do channel-wise shift
        h, w,_ = mask.shape
        img_masked_shifted = np.zeros(shape=(h, w, chs), dtype=mask.dtype)
        for ch in range(chs):
            shift_val = shift_list[ch]
            img_shifted = np.roll(img_masked[:,:,ch], shift=shift_val, axis=1)
            img_masked_shifted[:, :, ch] = img_shifted
        img_masked = img_masked_shifted

    img_prj = np.sum(img_masked, 2)
    img_prj_norm = img_prj / float(chs)
    # normalize
    # img_prj_norm = vis.normalize_1ch(img_prj)
    # vis.imshow_with_zoom('SSCSI', img=img_prj_norm, scale=1.0, interpolation=cv2.INTER_NEAREST)
    # cv2.waitKey()

    return img_prj_norm} 

params.py {import tensorflow as tf



FILENAME_DEFAULT_MODEL = 'models/model_64x11/model.ckpt-19199'


VALID_SPECTRAL_CHS = range(0,31)
N_VALID_SPECTRALS = len(VALID_SPECTRAL_CHS)
TF_DATA_TYPE = tf.float32
TF_CONV_KERNEL_SIZE = 3
TF_WEIGHT_DECAY_LAMBDA = 1e-08} 

autoencoder.model.py {import tensorflow as tf
import params


# 'c': convolutional
default_n_features_encoder = [params.N_VALID_SPECTRALS, 64, 64, 64, 64, 64, 64]
default_layer_type_encoder = ['c', 'c', 'c', 'c', 'c', 'c']
default_n_features_decoder = default_n_features_encoder[::-1]
default_layer_type_decoder = ['c', 'c', 'c', 'c', 'c', 'c']


def build_convoultiona_ae(list_n_features_encoder=default_n_features_encoder,
                          list_layer_type_encoder=default_layer_type_encoder,
                          list_n_features_decoder=default_n_features_decoder,
                          list_layer_type_decoder= default_layer_type_decoder,
                          is_trainable=True,
                          with_wd=True
                          ):
    #########################################################
    # Check dimensions
    #########################################################
    if list_n_features_encoder[-1] != list_n_features_decoder[0]:
        print('The output side of the encoder' \
              ' and the input size of decoder do not match')
        exit()
    if list_n_features_encoder[0] != list_n_features_decoder[-1]:
        print('The input side of the encoder' \
              ' and the output size of decoder do not match')
        exit()

    if (list_n_features_encoder[0] != params.N_VALID_SPECTRALS)\
            or(list_n_features_decoder[-1] != params.N_VALID_SPECTRALS):
        print('The input and the output sizes do not match with the n_channels')
        exit()

    if (len(list_n_features_encoder) != len(list_layer_type_encoder) + 1) \
            or (len(list_n_features_decoder) != len(list_layer_type_decoder) + 1):
        print('The input and the output sizes do not match with the n_channels')
        exit()

    n_convs_encoder = len(list_layer_type_encoder)
    n_convs_decoder = len(list_layer_type_decoder)

    #########################################################
    # Set placeholders
    #########################################################
    # the shape should be (batchsize, psize, psize, n_channels
    x_data_node = tf.placeholder(params.TF_DATA_TYPE, name='data')
    x_data_out_node = tf.placeholder(params.TF_DATA_TYPE, name='data')
    ksize = params.TF_CONV_KERNEL_SIZE

    # for weight decay
    conv_weight_list = []

    #########################################################
    # Build the encoder
    #########################################################
    layer_name_base = 'encoder'
    response = x_data_node
    for l in range(n_convs_encoder):
        l_type = list_layer_type_encoder[l]
        layer_name = layer_name_base + '-conv' + str(l)

        n_feature_prev = list_n_features_encoder[l]
        n_feature_next = list_n_features_encoder[l + 1]

        if l_type == 'c' or l_type == 'p':
            if l_type == 'c':
                list_stride = [1, 1, 1, 1]
                pad = 'SAME'
            else:
                list_stride = [1, 2, 2, 1]
                pad = 'SAME'

            with tf.variable_scope(layer_name):
                conv_weight = tf.get_variable("weight",
                                              shape=[ksize, ksize,
                                                     n_feature_prev,
                                                     n_feature_next],
                                              initializer=tf.contrib.layers.xavier_initializer_conv2d(),
                                              trainable=is_trainable)
                conv_bias = tf.Variable(tf.zeros([n_feature_next],dtype=params.TF_DATA_TYPE),
                                        name='bias',
                                        trainable=is_trainable)
                conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
                response = tf.nn.bias_add(conv, conv_bias)

                if with_wd:
                    conv_weight_list.append(conv_weight)

                if l == (n_convs_encoder - 1):
                    response = tf.identity(response)
                else:
                    response = tf.nn.relu(response)
        else:
            print('A wrong layer type for the encoder')
            exit()

        if l == (n_convs_encoder - 1):
            response_code = response


    #########################################################
    # Build the decoder
    #########################################################
    layer_name_base = 'decoder'

    for l in range(n_convs_decoder):
        l_type = list_layer_type_decoder[l]
        layer_name = layer_name_base + '-conv' + str(l)

        n_feature_prev = list_n_features_decoder[l]
        n_feature_next = list_n_features_decoder[l + 1]

        if l_type == 'c':
            list_stride = [1, 1, 1, 1]
            pad = 'SAME'
            with tf.variable_scope(layer_name):
                conv_weight = tf.get_variable("weight",
                                              shape=[ksize, ksize,
                                                     n_feature_prev,
                                                     n_feature_next],
                                              initializer=tf.contrib.layers.xavier_initializer_conv2d(),
                                              trainable=is_trainable)
                conv_bias = tf.Variable(tf.zeros([n_feature_next], dtype=params.TF_DATA_TYPE),
                                        name='bias',
                                        trainable=is_trainable)
                conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
                response = tf.nn.bias_add(conv, conv_bias)
                if l == (n_convs_decoder - 1):
                    response = tf.nn.relu(response)

                else:
                    response = tf.nn.relu(response)

                if with_wd:
                    conv_weight_list.append(conv_weight)
        else:
            print('A wrong layer type for the decoder')
            exit()

    x_data_predicted_node = response

    #########################################################
    # define the loss - data term
    #########################################################
    data_loss = tf.reduce_mean(tf.square(x_data_predicted_node - x_data_out_node), name='training_error')
    training_error = data_loss
    testing_error = tf.Variable(0.0, name='var_testing_err')
    ph_testing_error = tf.placeholder(dtype=tf.float32)
    op_assign_testing_error = tf.assign(testing_error, ph_testing_error)
    testing_psnr = tf.Variable(0.0, name='var_testing_psnr')
    ph_testing_psnr = tf.placeholder(dtype=tf.float32)
    op_assign_testing_psnr = tf.assign(testing_psnr, ph_testing_psnr)
    #########################################################
    # define the loss - weight decay term
    #########################################################
    if with_wd:
        weight_lambda = params.TF_WEIGHT_DECAY_LAMBDA
        weight_decay_term\
            = weight_lambda * tf.add_n([tf.nn.l2_loss(v) for v in conv_weight_list])
        weight_decay_term /= len(conv_weight_list)
        training_error += weight_decay_term

    #########################################################
    # Add summaries
    #########################################################
    training_error_summary = tf.summary.scalar('training error', training_error)
    data_loss_summary = tf.summary.scalar('data_loss', data_loss)
    testing_error_summary = tf.summary.scalar('testing error', testing_error)
    testing_psnr_summary = tf.summary.scalar('testing psnr', testing_psnr)

    if with_wd:
        weight_decay_error_summary = tf.summary.scalar('weight decay error', weight_decay_term)
        summary_op_weight_decay = tf.summary.merge([weight_decay_error_summary])


    #########################################################
    # Add saver
    #########################################################
    saver = tf.train.Saver()

    summary_op_training = tf.summary.merge([training_error_summary])
    summary_op_data_loss = tf.summary.merge([data_loss_summary])
    summary_op_testing = tf.summary.merge([testing_error_summary])
    summary_op_testing_psnr = tf.summary.merge([testing_psnr_summary])


    #########################################################
    # Return model
    #########################################################
    model = {'x_data_node': x_data_node,
             'x_data_out_node': x_data_out_node,
             'x_data_predicted_node': x_data_predicted_node,
             'code': response_code,
             'training_error': training_error,
             'data_loss': data_loss,
             'ph_testing_error': ph_testing_error,
             'op_assign_testing_error': op_assign_testing_error,
             'ph_testing_psnr': ph_testing_psnr,
             'op_assign_testing_psnr': op_assign_testing_psnr,
             'summary_op_training': summary_op_training,
             'summary_op_data_loss': summary_op_data_loss,
             'summary_op_testing': summary_op_testing,
             'summary_op_testing_psnr': summary_op_testing_psnr,
             'saver': saver,
             }

    if with_wd:
        model['weight_decay_term'] = weight_decay_term
        model['summary_op_weight_decay'] = summary_op_weight_decay

    return model} 

recon.snapshot.reconstruction.py {import tensorflow as tf
import numpy as np
import cv2
import scipy.io as sio
from datetime import datetime

import modulation
import visualizer.drawer as vis
import recon.model as model_recon_basics
import recon.snapshot.model as model_recon_cassi
import recon.misc as misc
import autoencoder.model as ae_model

def recon_snapshot(img_snapshot=[],
                   img_mask=[],
                   gt_hs=[],
                   out_filename=[],
                   img_n_chs=31,
                   list_shift =  modulation.shift_ours,
                   list_shift_y = np.zeros(shape=(1,31)),
                   SINGLE_CASSI=False,
                   SSCSI=False,
                   param_rho=1e-01,
                   param_sparsity = 0.01,
                   param_lambda_alpha_fidelity=1e-01,
                   param_learning_rate=1e-01,
                   n_iters_ADMM=15,
                   n_iters_ADAM = 100,
                   ENABLE_ALPHA_FIDELITY=True,
                   list_n_features_encoder=ae_model.default_n_features_encoder,
                   list_layer_type_encoder=ae_model.default_layer_type_encoder,
                   list_n_features_decoder=ae_model.default_n_features_decoder,
                   list_layer_type_decoder=ae_model.default_layer_type_decoder,
                   filename_model='',
                   summary_dir='./summary_recon',
                   do_summarize=False,
                   GPU_ID=''):

    #########################################################
    # check if correct inputs are given
    #########################################################
    if img_snapshot == [] or img_mask == []:
        print('Not enough input images are given! Terminating....')
        exit()

    #########################################################
    # initialize
    #########################################################
    param_lambda = param_sparsity * param_rho
    img_h, img_w = img_snapshot.shape
    n_features_in_code = list_n_features_encoder[-1]
    img_coded = np.expand_dims(img_snapshot, axis=0)

    if SSCSI:
        mask3d = modulation.shift_random_mask(img_mask, shift=0.1)
    else:
        mask3d = modulation.generate_shifted_mask_cube(img_mask, chs=img_n_chs,
                                                       shift_list=list_shift,
                                                       shift_list_y=list_shift_y,
                                                        SINGLE_CASSI=SINGLE_CASSI)
    mask3d_tf = np.zeros(shape=(1, img_h, img_w, img_n_chs),
                         dtype=np.float32)
    mask3d_tf[0, :, :, :] = mask3d

    if gt_hs != []:
        data = np.expand_dims(gt_hs, axis=0)

    #########################################################
    # build the autoencoder and load pre-trained weights
    #########################################################
    graph_ae = tf.Graph()
    with graph_ae.as_default():
        model_ae = ae_model.build_convoultiona_ae(list_n_features_encoder=list_n_features_encoder,
                                               list_layer_type_encoder=list_layer_type_encoder,
                                               list_n_features_decoder=list_n_features_decoder,
                                               list_layer_type_decoder=list_layer_type_decoder,
                                               is_trainable=False)
        tf_var_dict = {}
        weight_dict = {}
        for v in tf.global_variables():
            #print v.name
            tf_var_dict[v.name] = v

        # load trained weights
        with tf.Session() as sess:
            saver = tf.train.Saver()
            saver.restore(sess, filename_model)
            for key in tf_var_dict.keys():
                tf_var = tf_var_dict[key]
                weight_value, = sess.run([tf_var])
                weight_dict[key] = weight_value



    #########################################################
    # build the decoder and encoder
    #########################################################
    graph_ae_separated = tf.Graph()
    with graph_ae_separated.as_default():
        model_encoder = model_recon_basics.build_encoder_ae(list_n_features_encoder=list_n_features_encoder,
                                                      list_layer_type_encoder=list_layer_type_encoder,
                                                      weight_dict=weight_dict)

        model_decoder = model_recon_basics.build_decoder_ae(list_n_features_decoder=list_n_features_decoder,
                                                      list_layer_type_decoder=list_layer_type_decoder,
                                                      weight_dict=weight_dict)

    #########################################################
    # build recon network
    #########################################################
    graph_recon_network = tf.Graph()
    with graph_recon_network.as_default():
        if ENABLE_ALPHA_FIDELITY:
            model_recon = model_recon_cassi.build_recon_network_dual(list_n_features_encoder=list_n_features_encoder,
                                                               list_layer_type_encoder=list_layer_type_encoder,
                                                               list_n_features_decoder=list_n_features_decoder,
                                                               list_layer_type_decoder=list_layer_type_decoder,
                                                               weight_dict=weight_dict,
                                                               img_h=img_h,
                                                               img_w=img_w,
                                                               img_chs=img_n_chs,
                                                               SINGLE_CASSI=SINGLE_CASSI,
                                                               list_shift=list_shift,
                                                               n_features_in_code=n_features_in_code,
                                                               rho=param_rho,
                                                               learning_rate=param_learning_rate,
                                                               lambda_alpha_fidelity=param_lambda_alpha_fidelity)
        else:
            model_recon = model_recon_cassi.build_recon_network(list_n_features_decoder=list_n_features_decoder,
                                                          list_layer_type_decoder=list_layer_type_decoder,
                                                          weight_dict=weight_dict,
                                                          img_h=img_h,
                                                          img_w=img_w,
                                                          img_chs=img_n_chs,
                                                          n_features_in_code=n_features_in_code,
                                                          rho=param_rho,
                                                          learning_rate=param_learning_rate)

    xk = model_recon['xk']
    op_assign_xk = model_recon['op_assign_xk']
    xk_ph = model_recon['xk_ph']
    zk = model_recon['zk']
    op_assign_zk = model_recon['op_assign_zk']
    zk_ph = model_recon['zk_ph']
    uk = model_recon['uk']
    op_assign_uk = model_recon['op_assign_uk']
    uk_ph = model_recon['uk_ph']
    img_gt = model_recon['img_gt']
    img_recon = model_recon['img_recon']
    img_prj = model_recon['img_prj']
    mask3d_ph = model_recon['mask3d']
    loss = model_recon['loss']
    loss_data = model_recon['loss_data']
    loss_admm = model_recon['loss_admm']
    loss_tv_feature = model_recon['loss_tv_feature']
    loss_tv_recon = model_recon['loss_tv_recon']
    loss_tv_spec = model_recon['loss_tv_spec']
    loss_reg_mag = model_recon['loss_reg_mag']
    optimizer = model_recon['optimizer']
    summary_op_loss = model_recon['summary_op_loss']

    ph_testing_psnr = model_recon['ph_testing_psnr']
    op_assign_testing_psnr = model_recon['op_assign_testing_psnr']
    summary_op_testing_psnr = model_recon['summary_op_testing_psnr']

    if ENABLE_ALPHA_FIDELITY:
        xk_from_encoder = model_recon['xk_from_encoder']
        loss_alpha_fidelity = model_recon['loss_alpha_fidelity']

    #########################################################
    # do recon
    #########################################################

    with graph_recon_network.as_default():
        with tf.Session() as sess:
            # saver = tf.train.Saver()
            sess.run(tf.global_variables_initializer())
            summary_writer = tf.summary.FileWriter(summary_dir, sess.graph)
            summary_writer.flush()
            step = 0

            for i_admm in range(n_iters_ADMM):
                print('ADMM - iteration: %d' % (i_admm))
                start_time = datetime.now()
                n_iters = n_iters_ADAM

                for i_nonlinear in range(n_iters):
                    if ENABLE_ALPHA_FIDELITY:
                        _, dual_encoder_code, \
                        l_total, l_data, l_admm, l_alpha_fidelity \
                            = sess.run([optimizer, xk_from_encoder,
                                        loss, loss_data, loss_admm, loss_alpha_fidelity],
                                       feed_dict={img_gt: img_coded,
                                                  mask3d_ph: mask3d_tf})

                        if i_nonlinear % 50 == 0:
                            print('iter: %d, total_loss: %6e, data_loss: %6e, admm_loss: %6e,' \
                                  ' alpha_loss: %6e,' \
                                  % (i_nonlinear, l_total, l_data, l_admm, l_alpha_fidelity))

                        if i_nonlinear == n_iters - 1:
                            # update xk (code)
                            #sess.run(op_assign_xk, feed_dict={xk_ph: dual_encoder_code})
                            pass
                    else:
                        _, \
                        l_total, l_data, l_admm, \
                        l_tv_f, l_tv_recon, l_tv_spec, \
                        l_reg_mag \
                            = sess.run([optimizer,
                                        loss, loss_data, loss_admm,
                                        loss_tv_feature, loss_tv_recon, loss_tv_spec,
                                        loss_reg_mag],
                                       feed_dict={img_gt: img_coded,
                                                  mask3d_ph: mask3d_tf})

                        if i_nonlinear % 50 == 0:
                            print('iter: %d, total_loss: %6e, data_loss: %6e, admm_loss: %6e, ' \
                                  ' tv_loss_f: %6e, tv_recon_loss: %6e, tv_spec_loss: %6e, ' \
                                  'reg_mag_loss: %6e' \
                                  % (i_nonlinear, l_total, l_data, l_admm,
                                     l_tv_f, l_tv_recon, l_tv_spec, l_reg_mag))



                    if i_nonlinear % 50 == 0:
                        if ENABLE_ALPHA_FIDELITY:
                            code, code_encoder, img_result = sess.run([xk, xk_from_encoder, img_recon])
                            # img_result_15 = vis.normalize_1ch(img_result[0, :, :, 15])
                            img_result_15 = img_result[0, :, :, 15]
                            temp_max = np.max(img_result)
                            temp_min = np.min(img_result)
                            img_result_15 = (img_result_15 - temp_min) / (temp_max - temp_min)

                            vis.imshow_with_zoom(GPU_ID + "recon data_tf", np.power(img_result_15, 1 / 2.2), scale=1.0)
                            #vis.visualize_sparse_code(code, rows=8, cols=8, title=GPU_ID + 'code_tf', scale=0.25)
                            #vis.visualize_sparse_code(code_encoder, rows=8, cols=8, title=GPU_ID + 'code_tf_encoder', scale=0.25)

                            img_result_resize = cv2.resize(img_result[0], dsize=(int(img_w / 5), int(img_h / 5)))
                            img_result_resize = np.expand_dims(img_result_resize, 0)

                            if gt_hs != []:
                                data_resize = cv2.resize(data[0], dsize=(int(img_w / 5), int(img_h / 5)))
                                data_resize = np.expand_dims(data_resize, 0)

                                vis.draw_the_comparison(img_result_resize, data_resize, title=GPU_ID + 'image recon comparison')

                                gt_15 = data[0, :, :, 15]
                                temp_max = np.max(gt_15)
                                temp_min = np.min(gt_15)
                                gt_15 = (gt_15 - temp_min) / (temp_max - temp_min)

                                vis.imshow_with_zoom(GPU_ID + "GT", np.power(gt_15, 1 / 2.2),
                                                     scale=1.0)
                                test_diff_sqr = np.square(img_result - data)
                                test_diff_sqr_avg = np.average(test_diff_sqr)
                                test_psnr = -10.0 * np.log10(test_diff_sqr_avg)
                                print('test_psnr: %.4f' % (test_psnr))
                            else:
                                temp_max = np.max(img_result_resize)
                                temp_min = np.min(img_result_resize)
                                img_result_resize = (img_result_resize - temp_min) / (temp_max - temp_min)
                                vis.draw_the_comparison(img_result_resize,
                                                        title=GPU_ID + 'image recon comparison',
                                                        compute_psnr=False)
                        else:
                            code, img_prj_est, img_result \
                                = sess.run([xk, img_prj, img_recon],
                                           feed_dict={mask3d_ph: mask3d_tf})


                            img_result_15 = img_result[0, :, :, 15]
                            temp_max = np.max(img_result)
                            temp_min = np.min(img_result)
                            img_result_15 = (img_result_15 - temp_min) / (temp_max - temp_min)
                            vis.imshow_with_zoom("recon data_tf", np.power(img_result_15, 1 / 2.2), scale=1.0)
                            vis.visualize_sparse_code(code, rows=8, cols=8, title='code_tf', scale=0.25)
                            img_prj_est_vis = vis.normalize_1ch(img_prj_est[0])
                            vis.imshow_with_zoom('estimated SSCSI', img_prj_est_vis, scale=1.0)

                            img_result_resize = cv2.resize(img_result[0], dsize=(int(img_w / 5), int(img_h / 5)))
                            img_result_resize = np.expand_dims(img_result_resize, 0)
                            if gt_hs != []:
                                data_resize = cv2.resize(data[0], dsize=(int(img_w / 5), int(img_h / 5)))
                                data_resize = np.expand_dims(data_resize, 0)
                                vis.draw_the_comparison(img_result_resize, data_resize, title='image recon comparison')
                                test_diff_sqr = np.square(img_result - data)
                                test_diff_sqr_avg = np.average(test_diff_sqr)
                                test_psnr = -10.0 * np.log10(test_diff_sqr_avg)
                                print('test_psnr: %.4f' % (test_psnr))
                            else:
                                temp_max = np.max(img_result_resize)
                                temp_min = np.min(img_result_resize)
                                img_result_resize = (img_result_resize - temp_min) / (temp_max - temp_min)
                                vis.draw_the_comparison(img_result_resize, img_result_resize,
                                                        title='image recon comparison',
                                                        compute_psnr=False)
                        cv2.waitKey(100)

                        # compute PSNR
                        if do_summarize == True and gt_hs != []:
                            code, img_result = sess.run([xk, img_recon])
                            test_diff_sqr = np.square(img_result - data)
                            test_diff_sqr_avg = np.average(test_diff_sqr)
                            psnr_val = -10.0 * np.log10(test_diff_sqr_avg)
                            sess.run(op_assign_testing_psnr, feed_dict={ph_testing_psnr: psnr_val})
                            summary_str = sess.run(summary_op_testing_psnr)
                            summary_writer.add_summary(summary_str, step)
                            summary_writer.flush()

                    step = step + 1

                # get variabels from TF
                xk1_val, img_val, zk_val, uk_val = sess.run([xk, img_recon, zk, uk])

                ############################################ for real image
                img_val[img_val > 1.0] = 1.0
                img_val[img_val < 0.0] = 0.0
                ############################################

                # update z
                np_G_xk1_val = misc.np_del_operator(img_val)
                zk1_val = misc.soft_threshold(np_G_xk1_val + uk_val, param_lambda, param_rho)

                #  update u
                uk1_val = uk_val + np_G_xk1_val - zk1_val

                # assign updated variables to TF
                sess.run([op_assign_zk], feed_dict={zk_ph: zk1_val})
                sess.run([op_assign_uk], feed_dict={uk_ph: uk1_val})

                end_time = datetime.now()
                elapsed_time = end_time - start_time
                print('elapsed time for 1 ADMM iteration: ' + str(elapsed_time))

    cv2.waitKey(5000)

    wvls2b = np.arange(400, 701, 10)
    wvls2b = wvls2b.astype(np.float32)
    if out_filename != []:
        out_dict =  {'x_recon': np.squeeze(img_result),
                      'wvls2b': wvls2b}
        sio.savemat(out_filename, out_dict)
        # if gt_hs != []:
        #     out_dict_gt = {'x_recon': np.squeeze(gt_hs),
        #                    'wvls2b': wvls2b}
        #     sio.savemat('gt.mat', out_dict_gt)

    return img_result, wvls2b} 

recon.model {import tensorflow as tf
import params

def build_encoder_ae(list_n_features_encoder=[],
                     list_layer_type_encoder=[],
                     is_trainable=False,
                     weight_dict={}):
    n_convs_encoder = len(list_layer_type_encoder)
    is_reusable = True

    #########################################################
    # Set placeholders
    #########################################################
    # the shape should be (batchsize, psize, psize, n_channels
    x_data_node = tf.placeholder(params.TF_DATA_TYPE, name='data')

    #########################################################
    # Build the encoder
    #########################################################
    layer_name_base = 'encoder'
    response = x_data_node
    for l in range(n_convs_encoder):
        layer_name = layer_name_base + '-conv' + str(l)
        list_stride = [1, 1, 1, 1]
        pad = 'SAME'

        with tf.variable_scope(layer_name, reuse=is_reusable):
            key_weight = layer_name + "/weight:0"
            weight_val = weight_dict[key_weight]
            conv_weight = tf.constant(weight_val, name="weight")
            key_bias = layer_name + "/bias:0"
            bias_val = weight_dict[key_bias]
            conv_bias = tf.constant(bias_val, name="bias")
            conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
            response = tf.nn.bias_add(conv, conv_bias)
            if l == (n_convs_encoder - 1):
                response = tf.identity(response)
            else:
                response = tf.nn.relu(response)

    sparse_code_alpha = tf.identity(response, name='sparse_code_alpha')
    #########################################################
    # Return model
    #########################################################
    model = {'x_data_node': x_data_node,
             'sparse_code_alpha': sparse_code_alpha}
    return model


def build_decoder_ae(list_n_features_decoder=[],
                     list_layer_type_decoder=[],
                     is_trainable=False,
                     weight_dict={}):
    n_convs_decoder = len(list_layer_type_decoder)
    is_resuable = True
    #########################################################
    # Set placeholders
    #########################################################
    # the shape should be (batchsize, psize, psize, n_channels
    sparse_code_alpha = tf.placeholder(params.TF_DATA_TYPE, name='alpha')

    #########################################################
    # Build the decoder
    #########################################################
    layer_name_base = 'decoder'
    response = sparse_code_alpha

    for l in range(n_convs_decoder):
        layer_name = layer_name_base + '-conv' + str(l)

        list_stride = [1, 1, 1, 1]
        pad = 'SAME'
        with tf.variable_scope(layer_name, reuse=is_resuable):
            key_weight = layer_name + "/weight:0"
            weight_val = weight_dict[key_weight]
            conv_weight = tf.constant(weight_val, name="weight")
            key_bias = layer_name + "/bias:0"
            bias_val = weight_dict[key_bias]
            conv_bias = tf.constant(bias_val, name="bias")
            conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
            response = tf.nn.bias_add(conv, conv_bias)
            response = tf.nn.relu(response)

    img_recon = tf.identity(response, name='img_recon')

    #########################################################
    # Return model
    #########################################################
    model = {'sparse_code_alpha': sparse_code_alpha,
             'img_recon': img_recon,
             }
    return model} 

recon.snapshot.model {import tensorflow as tf
import numpy as np
import params


def build_recon_network(list_n_features_decoder=[],
                        list_layer_type_decoder=[],
                        weight_dict=[],
                        img_h=-1,
                        img_w=-1,
                        img_chs=31,
                        n_features_in_code=64,
                        rho=1.0,
                        learning_rate=1e-01):
    n_convs_decoder = len(list_layer_type_decoder)
    is_reusable = True
    #########################################################
    # Set placeholders
    #########################################################
    # the shape should be (batchsize, psize, psize, n_channels
    # sparse_code_alpha = tf.placeholder(params.TF_DATA_TYPE, name='alpha')
    code_shape = [1, img_h, img_w, n_features_in_code]
    img_gradient_shape = [1, img_h - 1, img_w - 1, img_chs, 2]
    #code_gradient_shape = [1, img_h - 1, img_w - 1, n_features_in_code]

    img_gt = tf.placeholder(params.TF_DATA_TYPE, name='img_gt')
    mask3d = tf.placeholder(params.TF_DATA_TYPE, name='mask3d')

    # xk = tf.Variable(tf.abs(tf.random_normal(shape=code_shape))*0.001, name='xk')
    xk = tf.Variable(tf.ones(shape=code_shape) * 0.0001, name='xk')
    xk_ph = tf.placeholder(params.TF_DATA_TYPE, name='xk_ph')
    op_assign_xk = xk.assign(xk_ph)

    # admm_zk = tf.Variable(tf.abs(tf.random_normal(shape=code_shape))*0.512, name='admm_zk')
    zk = tf.Variable(tf.ones(shape=img_gradient_shape) * 0.0001, name='zk', trainable=False)
    zk_ph = tf.placeholder(params.TF_DATA_TYPE, name='zk_ph')
    op_assign_zk = zk.assign(zk_ph)

    uk = tf.Variable(tf.ones(shape=img_gradient_shape) * 0.0001, name='uk', trainable=False)
    uk_ph = tf.placeholder(params.TF_DATA_TYPE, name='uk_ph')
    op_assign_uk = uk.assign(uk_ph)
    #########################################################
    # Build the decoder
    #########################################################
    layer_name_base = 'decoder'
    response = xk

    for l in range(n_convs_decoder):
        layer_name = layer_name_base + '-conv' + str(l)

        list_stride = [1, 1, 1, 1]
        pad = 'SAME'
        with tf.variable_scope(layer_name, reuse=is_reusable):
            key_weight = layer_name + "/weight:0"
            weight_val = weight_dict[key_weight]
            conv_weight = tf.constant(weight_val, name="weight")
            key_bias = layer_name + "/bias:0"
            bias_val = weight_dict[key_bias]
            conv_bias = tf.constant(bias_val, name="bias")
            conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
            response = tf.nn.bias_add(conv, conv_bias)
            response = tf.nn.relu(response)

    # img_recon = response
    img_recon = tf.identity(response, name='img_recon')

    # apply coded mask
    img_masked = tf.multiply(img_recon, mask3d, name='masking')
    # projection to 2D
    img_prj = tf.reduce_sum(img_masked, 3)
    # normlaize
    img_prj = img_prj / np.float(img_chs)

    # loss data
    diff = img_prj - img_gt
    loss_data = 1.0 * 1e+00 * 0.5 * tf.reduce_mean(tf.square(diff))

    # loss ADMM
    G_xk_vertical = img_recon[:, 1:, :, :] - img_recon[:, :-1, :, :]
    G_xk_horizontal = img_recon[:, :, 1:, :] - img_recon[:, :, :-1, :]
    G_xk_vertical = G_xk_vertical[:, :, :-1, :]
    G_xk_horizontal = G_xk_horizontal[:, :-1, : :]
    G_xk = tf.stack([G_xk_vertical, G_xk_horizontal], axis=4)
    #G_xk = tf.square(G_xk_vertical) + tf.square(G_xk_horizontal)
    diff = G_xk - zk + uk
    #diff = xk - zk + uk
    loss_admm = 1.0*0.5*rho*tf.reduce_mean(tf.square(diff))

    # regularization on code
    # tv on featrue
    n_total_pixels = img_h * img_w * img_chs
    loss_tv_feature = 0.0 * 1e-02 * (tf.nn.l2_loss(xk[:, 1:, :, :] - xk[:, :img_h - 1, :, :]) / n_total_pixels
                                     + tf.nn.l2_loss(xk[:, :, 1:, :] - xk[:, :, :img_w - 1, :]) / n_total_pixels)

    # tv on recon image
    loss_tv_recon = 0.0 * 1e-02 * (
    tf.nn.l2_loss(img_recon[:, 1:, :, :] - img_recon[:, :img_h - 1, :, :]) / n_total_pixels
    + tf.nn.l2_loss(img_recon[:, :, 1:, :] - img_recon[:, :, :img_w - 1, :]) / n_total_pixels)

    # tv for spectral dimension
    loss_tv_spectrum \
        = 0.0 * 1e-05 * 1.0 * tf.nn.l2_loss(img_recon[:, :, :, 1:] - img_recon[:, :, :, :img_chs - 1]) / n_total_pixels

    # reg
    loss_reg_mag = 0.0 * 1e-06 * 0.5 * tf.reduce_mean((tf.square(xk)))
    loss = loss_data + loss_admm \
           + loss_tv_feature + loss_tv_recon + loss_tv_spectrum \
           + loss_reg_mag
    loss = loss * 1e+00

    # data term
    #optimizer = tf.train.AdadeltaOptimizer(learning_rate=1e-01).minimize(loss)
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)

    # add summary
    loss_summary = tf.scalar_summary('loss', loss)
    summary_op_loss = tf.merge_summary([loss_summary])

    testing_psnr = tf.Variable(0.0, name='var_testing_psnr')
    ph_testing_psnr = tf.placeholder(dtype=tf.float32)
    op_assign_testing_psnr = tf.assign(testing_psnr, ph_testing_psnr)
    testing_psnr_summary = tf.scalar_summary('testing psnr', testing_psnr)
    summary_op_testing_psnr = tf.merge_summary([testing_psnr_summary])

    #########################################################
    # Return model
    #########################################################
    model = {'xk': xk,
             'op_assign_xk': op_assign_xk,
             'xk_ph': xk_ph,
             'zk': zk,
             'op_assign_zk': op_assign_zk,
             'zk_ph': zk_ph,
             'uk': uk,
             'op_assign_uk': op_assign_uk,
             'uk_ph': uk_ph,
             'img_gt': img_gt,
             'mask3d': mask3d,
             'img_recon': img_recon,
             'img_prj': img_prj,
             'loss': loss,
             'loss_data': loss_data,
             'loss_admm': loss_admm,
             'loss_tv_feature': loss_tv_feature,
             'loss_tv_recon': loss_tv_recon,
             'loss_tv_spec': loss_tv_spectrum,
             'loss_reg_mag': loss_reg_mag,
             'optimizer': optimizer,
             'summary_op_loss': summary_op_loss,
             'op_assign_testing_psnr': op_assign_testing_psnr,
             'summary_op_testing_psnr': summary_op_testing_psnr,
             'ph_testing_psnr': ph_testing_psnr
             }
    return model


def build_recon_network_dual(list_n_features_encoder=[],
                             list_layer_type_encoder=[],
                             list_n_features_decoder=[],
                             list_layer_type_decoder=[],
                             weight_dict=[],
                             img_h=-1,
                             img_w=-1,
                             img_chs=31,
                             SINGLE_CASSI=False,
                             list_shift=[],
                             n_features_in_code=64,
                             rho=1e-01,
                             lambda_alpha_fidelity=1e-01,
                             learning_rate=1e-01):

    n_convs_encoder = len(list_layer_type_encoder)
    n_convs_decoder = len(list_layer_type_decoder)
    is_reusable = True
    #########################################################
    # Set placeholders
    #########################################################
    # the shape should be (batchsize, psize, psize, n_channels
    # sparse_code_alpha = tf.placeholder(params.TF_DATA_TYPE, name='alpha')
    code_shape = [1, img_h, img_w, n_features_in_code]
    img_gradient_shape = [1, img_h - 1, img_w - 1, img_chs, 2]
    # code_gradient_shape = [1, img_h - 1, img_w - 1, n_features_in_code]

    img_gt = tf.placeholder(params.TF_DATA_TYPE, name='img_gt')
    mask3d = tf.placeholder(params.TF_DATA_TYPE, name='mask3d')

    # xk = tf.Variable(tf.abs(tf.random_normal(shape=code_shape))*0.001, name='xk')
    xk = tf.Variable(tf.ones(shape=code_shape) * 0.0001, name='xk')
    xk_ph = tf.placeholder(params.TF_DATA_TYPE, name='xk_ph')
    op_assign_xk = xk.assign(xk_ph)

    # admm_zk = tf.Variable(tf.abs(tf.random_normal(shape=code_shape))*0.512, name='admm_zk')
    zk = tf.Variable(tf.ones(shape=img_gradient_shape) * 0.0001, name='zk', trainable=False)
    zk_ph = tf.placeholder(params.TF_DATA_TYPE, name='zk_ph')
    op_assign_zk = zk.assign(zk_ph)

    uk = tf.Variable(tf.ones(shape=img_gradient_shape) * 0.0001, name='uk', trainable=False)
    uk_ph = tf.placeholder(params.TF_DATA_TYPE, name='uk_ph')
    op_assign_uk = uk.assign(uk_ph)
    #########################################################
    # Build the decoder
    #########################################################
    layer_name_base = 'decoder'
    response = xk

    for l in range(n_convs_decoder):
        layer_name = layer_name_base + '-conv' + str(l)

        list_stride = [1, 1, 1, 1]
        pad = 'SAME'
        with tf.variable_scope(layer_name, reuse=is_reusable):
            key_weight = layer_name + "/weight:0"
            weight_val = weight_dict[key_weight]
            conv_weight = tf.constant(weight_val, name="weight")
            key_bias = layer_name + "/bias:0"
            bias_val = weight_dict[key_bias]
            conv_bias = tf.constant(bias_val, name="bias")
            conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
            response = tf.nn.bias_add(conv, conv_bias)
            response = tf.nn.relu(response)

    # img_recon = response
    img_recon = tf.identity(response, name='img_recon')
    # apply coded mask
    img_masked = tf.multiply(img_recon, mask3d, name='masking')
    if SINGLE_CASSI:
        list_chs = []
        for ch in range(img_chs):
            shift_val = list_shift[ch]
            img_masked_ch = img_masked[:, :, :, ch]
            tensor_left = img_masked_ch[:, :, (img_w - shift_val):]
            tensor_right = img_masked_ch[:, :, 0:(img_w - shift_val)]
            tensor_concat = tf.concat(2, [tensor_left, tensor_right])
            list_chs.append(tensor_concat)
        img_masked = tf.stack(list_chs, axis=3)


    # projection to 2D
    img_prj = tf.reduce_sum(img_masked, 3)
    # normlaize
    img_prj = img_prj / np.float(img_chs)


    #########################################################
    # Build the encoder
    #########################################################
    layer_name_base = 'encoder'
    response = img_recon
    for l in range(n_convs_encoder):
        layer_name = layer_name_base + '-conv' + str(l)
        list_stride = [1, 1, 1, 1]
        pad = 'SAME'

        with tf.variable_scope(layer_name, reuse=is_reusable):
            key_weight = layer_name + "/weight:0"
            weight_val = weight_dict[key_weight]
            conv_weight = tf.constant(weight_val, name="weight")
            key_bias = layer_name + "/bias:0"
            bias_val = weight_dict[key_bias]
            conv_bias = tf.constant(bias_val, name="bias")
            conv = tf.nn.conv2d(response, conv_weight, strides=list_stride, padding=pad)
            response = tf.nn.bias_add(conv, conv_bias)
            if l == (n_convs_encoder - 1):
                response = tf.identity(response)
            else:
                response = tf.nn.relu(response)

    xk_from_encoder = tf.identity(response, name='sparse_code_alpha')

    #########################################################
    # Build loss functions
    #########################################################
    # loss data
    diff = img_prj - img_gt
    loss_data = 0.5 * tf.reduce_mean(tf.square(diff))

    # alpha fidelity
    diff_xk = xk - xk_from_encoder
    loss_alpha_fidelity = 1.0 * lambda_alpha_fidelity * 0.5 * tf.reduce_mean(tf.square(diff_xk))

    # loss ADMM
    G_xk_vertical = img_recon[:, 1:, :, :] - img_recon[:, :-1, :, :]
    G_xk_horizontal = img_recon[:, :, 1:, :] - img_recon[:, :, :-1, :]
    G_xk_vertical = G_xk_vertical[:, :, :-1, :]
    G_xk_horizontal = G_xk_horizontal[:, :-1, ::]
    G_xk = tf.stack([G_xk_vertical, G_xk_horizontal], axis=4)
    # G_xk = tf.square(G_xk_vertical) + tf.square(G_xk_horizontal)
    diff = G_xk - zk + uk
    # diff = xk - zk + uk
    loss_admm = 1.0 * 0.5 * rho * tf.reduce_mean(tf.square(diff))


   # regularization on code
    # tv on featrue
    #######################################################################
    # IGNORE
    #######################################################################
    n_total_pixels = img_h * img_w * img_chs
    loss_tv_feature = 0.0 * 1e-02 * (tf.nn.l2_loss(xk[:, 1:, :, :] - xk[:, :img_h - 1, :, :]) / n_total_pixels
                                     + tf.nn.l2_loss(xk[:, :, 1:, :] - xk[:, :, :img_w - 1, :]) / n_total_pixels)

    # tv on recon image
    # -02
    loss_tv_recon = 0.0 * 1e-03 * (
        tf.nn.l2_loss(img_recon[:, 1:, :, :] - img_recon[:, :img_h - 1, :, :]) / n_total_pixels
        + tf.nn.l2_loss(img_recon[:, :, 1:, :] - img_recon[:, :, :img_w - 1, :]) / n_total_pixels)

    # tv for spectral dimension
    loss_tv_spectrum \
        = 0.0 * 1e-08 * 1.0 * tf.nn.l2_loss(img_recon[:, :, :, 1:] - img_recon[:, :, :, :img_chs - 1]) / n_total_pixels

    # reg
    loss_reg_mag = 0.0 * 1e-03 * 0.5 * tf.reduce_mean((tf.square(xk)))
    #######################################################################


    loss = loss_data + loss_admm + loss_alpha_fidelity
           #+ loss_tv_feature + loss_tv_recon + loss_tv_spectrum \
           #+ loss_reg_mag
    loss = loss * 1e+00

    # data term
    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)

    # add summary
    loss_summary = tf.summary.scalar('loss', loss)
    summary_op_loss = tf.summary.merge([loss_summary])

    testing_psnr = tf.Variable(0.0, name='var_testing_psnr')
    ph_testing_psnr = tf.placeholder(dtype=tf.float32)
    op_assign_testing_psnr = tf.assign(testing_psnr, ph_testing_psnr)
    testing_psnr_summary = tf.summary.scalar('testing psnr', testing_psnr)
    summary_op_testing_psnr = tf.summary.merge([testing_psnr_summary])


    #########################################################
    # Return model
    #########################################################
    model = {'xk': xk,
             'op_assign_xk': op_assign_xk,
             'xk_ph': xk_ph,
             'xk_from_encoder': xk_from_encoder,
             'zk': zk,
             'op_assign_zk': op_assign_zk,
             'zk_ph': zk_ph,
             'uk': uk,
             'op_assign_uk': op_assign_uk,
             'uk_ph': uk_ph,
             'img_gt': img_gt,
             'mask3d': mask3d,
             'img_recon': img_recon,
             'img_prj': img_prj,
             'loss': loss,
             'loss_data': loss_data,
             'loss_alpha_fidelity': loss_alpha_fidelity,
             'loss_admm': loss_admm,
             'loss_tv_feature': loss_tv_feature,
             'loss_tv_recon': loss_tv_recon,
             'loss_tv_spec': loss_tv_spectrum,
             'loss_reg_mag': loss_reg_mag,
             'optimizer': optimizer,
             'summary_op_loss': summary_op_loss,
             'op_assign_testing_psnr': op_assign_testing_psnr,
             'summary_op_testing_psnr': summary_op_testing_psnr,
             'ph_testing_psnr': ph_testing_psnr
             }
    return model} 

recon.misc {import numpy as np


def np_del_operator(xk):
    batchsize, height, width, n_chs = xk.shape
    G = np.zeros(shape=(batchsize, height, width, n_chs, 2),
                 dtype=xk.dtype)

    # y gradient
    G[:,:-1,:,:,0] -= xk[:,:-1,:,:]
    G[:,:-1,:,:,0] += xk[:,1:,:,:]

    # x gradient
    G[:,:,:-1,:,1] -= xk[:,:,:-1,:]
    G[:,:,:-1,:,1] += xk[:,:,1:,:]

    G = G[:, :-1, :-1, :, :]
    return G

def soft_threshold(v, l, r):
    threshold_val = l/r
    print('before: ')
    print(threshold_val)
    print(np.max(v))
    print(np.min(v))
    # print v.shape
    vshape = v.shape
    v = v.flatten()
    v1 = np.copy(v)
    v2 = np.copy(v)
    v3 = np.copy(v)
    # print v.shape

    abs_v = np.abs(v)
    v1[v1 > threshold_val] -= threshold_val
    v2[abs_v < threshold_val] = 0
    v3[v3 < -threshold_val] += threshold_val

    v[v > threshold_val] = v1[v > threshold_val]
    v[abs_v < threshold_val] = 0
    v[v < -threshold_val] = v3[v < -threshold_val]

    v = np.reshape(v, newshape=vshape)

    #print threshold_val
    print('after: ')
    print(np.max(v))
    print(np.min(v))
    return v} 


basically these are the important files linked with the algorithm 1 in this paper , what i want is to implement it for me in pytorch correctly exactly as it is there with no mistakes and explaining to me what each file does , i want ur implementation to include minimal files and be correct as mentioned in the code above and the associated paper, you can suppose that the autoencoder is already impelemnted and trained in pytorch and is good to be used (just like the reference impelemntation)